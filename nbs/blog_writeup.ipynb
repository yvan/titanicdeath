{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# titanicdeath.com\n",
    "\n",
    "this is the writeup for <a href=\"http://titanicdeath.com\">titanicdeath.com</a>, besides having a turly fantastic name, this little website i created tells you whether or not you would be likely to die on the titanic provided some small amount of personal information.\n",
    "\n",
    "the first question you are probably asking is: <b>why did i die?</b> (or) <b>why did i live?</b>\n",
    "\n",
    "the biggest determining factor in whether you lived or died is your gender. <b>females were much more likely to suvive the sinking of the titanic than men.</b> if you have ever heard the phrase 'women and children first' you will have an intuitive understanding of why this is. still, don't take my word for it, let's examine some evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#let us load the logistic regression model used\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "logreg = joblib.load('../titanicdeath/static/logreg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficents</th>\n",
       "      <th>inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.749007</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.311200</td>\n",
       "      <td>age*class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.085150</td>\n",
       "      <td>fare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.129140</td>\n",
       "      <td>is_alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.261762</td>\n",
       "      <td>embarked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287163</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.398234</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.201527</td>\n",
       "      <td>sex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   coefficents     inputs\n",
       "0    -0.749007      class\n",
       "7    -0.311200  age*class\n",
       "3    -0.085150       fare\n",
       "6     0.129140   is_alone\n",
       "4     0.261762   embarked\n",
       "2     0.287163        age\n",
       "5     0.398234      title\n",
       "1     2.201527        sex"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let us have a look at the inputs\n",
    "# and how strongly the predict suvival\n",
    "coefficients = pd.DataFrame(logreg.coef_[0])\n",
    "coefficients.columns = ['coefficents']\n",
    "coefficients['inputs'] = pd.Series(['class', 'sex', 'age', 'fare', 'embarked', 'title', 'is_alone', 'age*class'])\n",
    "coefficients.sort_values(by='coefficents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the 'sex' input has the biggest effect on suvival\n",
    "\n",
    "in our data i assigned women a value of 1 and men a value of 0. the positive coefficient of 2.2 means that <b>as we go more in a positive direction (towards 1/female gender) we are more likely to survive</b> and as we go more in a negative direction (towards 0/male gender) we are less likely to survive.\n",
    "\n",
    "<br/>\n",
    "the 'class' input has the next biggest effect on survival\n",
    "\n",
    "in our data class was either a 1 (first), 2 (second), or 3 (third class). the negative value of the coefficient means that the more any one passenger's class goes in a positive direction (towards 3/third class) they become less likely to survive. <b>if a user's class input value is more towards the negative (towards 1/first class) that passenger becomes more likely to survive</b>. this makes some sense, often times first class passengers receive benefits, one of the benefits on a sinking ship may have been easier access to lifeboats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some of the inputs were too strange to ask. for example as an inhabitant of the modern day you do not possess a 'port of embarkation.' to resolve this i simply pulled a value at random from the dataset for 'port of embarkation.'\n",
    "\n",
    "\n",
    "i could have made the sampling process better by restricitng it to passengers whose data points matched those given by visitors to titanicdeath.com, so for example if a user marked that they usually travel first class, i could have sampled ports of embarkation only from passengers that travelled fist class on the titanic. i chose not to do this to add some element of randomness to the site. i think of everything i do as an experimental product; most products require some variable reward (this is also a little bit more fun)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.078280156772079126"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "this bit of code takes in a passenger's input values\n",
    "and tells us what probability that user has of living\n",
    "and dying. the number shows our probability of survival\n",
    "'''\n",
    "\n",
    "age = 2\n",
    "fare = 0\n",
    "embarkation = 2\n",
    "title = 1\n",
    "is_alone = 1\n",
    "age_class = 6\n",
    "\n",
    "passenger_class = 3 \n",
    "sex = 0 \n",
    "\n",
    "passenger_input = pd.DataFrame([[passenger_class, sex, age, fare, embarkation, title, is_alone, age_class]])\n",
    "pred = logreg.predict_proba(passenger_input)\n",
    "pred[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43427750040904095"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "if we change the sex from male to female 0->1\n",
    "we see a huge improvement in suvival rate.\n",
    "'''\n",
    "passenger_class = 3 \n",
    "sex = 1\n",
    "\n",
    "passenger_input = pd.DataFrame([[passenger_class, sex, age, fare, embarkation, title, is_alone, age_class]])\n",
    "pred = logreg.predict_proba(passenger_input)\n",
    "pred[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77444683956853377"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "if we change the class from 3->1\n",
    "we improve odds of suvival even further\n",
    "'''\n",
    "passenger_class = 1 \n",
    "sex = 1\n",
    "\n",
    "passenger_input = pd.DataFrame([[passenger_class, sex, age, fare, embarkation, title, is_alone, age_class]])\n",
    "pred = logreg.predict_proba(passenger_input)\n",
    "pred[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you would like to explore this data yourself there is a really nice tutorial here:\n",
    "\n",
    "https://www.kaggle.com/c/titanic\n",
    "\n",
    "https://www.kaggle.com/startupsci/titanic/titanic-data-science-solutions\n",
    "\n",
    "if you are interested in machine learning and a very good overview of how an algorithm like logistic regression works i highly recommend you check out the first 3 lectures of andrew ng's coursera course:\n",
    "\n",
    "https://www.coursera.org/learn/machine-learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
